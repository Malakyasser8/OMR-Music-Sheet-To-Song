{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OMR Music Sheet to A MP3 file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "from skimage import img_as_ubyte\n",
    "import skimage as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.exposure import histogram\n",
    "from skimage.filters import threshold_otsu,threshold_local,median, unsharp_mask\n",
    "from matplotlib.pyplot import bar\n",
    "from skimage.color import rgb2gray,rgb2hsv\n",
    "from commonfunctions import *\n",
    "from scipy.ndimage import rotate\n",
    "from skimage.morphology import binary_erosion, binary_dilation, binary_closing, skeletonize, thin, binary_opening, remove_small_objects\n",
    "from skimage.measure import find_contours\n",
    "from skimage.draw import rectangle\n",
    "from skimage.transform import resize\n",
    "from scipy.stats import mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equation(image):\n",
    "    shape=image.shape\n",
    "    H=np.zeros(256)\n",
    "    for x in range(0,shape[0]):\n",
    "        for y in range(0,shape[1]):\n",
    "            H[image[x][y]]+=1\n",
    "\n",
    "    return H\n",
    "\n",
    "\n",
    "# def getThresholdRawan(img):\n",
    "#     counts, _ = np.histogram(img, bins=256, range=(0, 256))\n",
    "    \n",
    "#     total_pixels = np.sum(counts)\n",
    "#     print(total_pixels)\n",
    "#     Tinit = int(round(np.sum([i * counts[i] for i in range(256)]) / total_pixels))\n",
    "\n",
    "    \n",
    "#     while True:\n",
    "#         if np.sum(counts[:Tinit]) == 0 or np.sum(counts[Tinit:]) == 0:\n",
    "#             return Tinit\n",
    "#         lower = np.sum([i * counts[i] for i in range(Tinit)]) / np.sum(counts[:Tinit])\n",
    "#         higher = np.sum([i * counts[i] for i in range(Tinit, 256)]) / np.sum(counts[Tinit:])\n",
    "#         new_T = int((lower + higher) / 2)\n",
    "#         if new_T == Tinit:\n",
    "#             return new_T\n",
    "#         Tinit = new_T\n",
    "\n",
    "# def partition_imageRawan(img, n_partitions_horiz, n_partitions_vert):\n",
    "#     print(img.shape)\n",
    "#     height, width = img.shape\n",
    "#     row_step = height // n_partitions_horiz\n",
    "#     col_step = width // n_partitions_vert\n",
    "    \n",
    "#     binary_img = np.zeros_like(img)\n",
    "    \n",
    "#     for i in range(n_partitions_horiz):\n",
    "#         for j in range(n_partitions_vert):\n",
    "#             row_start = i * row_step\n",
    "#             row_end = (i + 1) * row_step if i < n_partitions_horiz - 1 else height\n",
    "#             col_start = j * col_step\n",
    "#             col_end = (j + 1) * col_step if j < n_partitions_vert - 1 else width\n",
    "            \n",
    "#             img_section = img[row_start:row_end, col_start:col_end]\n",
    "#             threshold = getThresholdRawan(img_section)\n",
    "#             binary_section = img_section > threshold\n",
    "#             binary_img[row_start:row_end, col_start:col_end] = binary_section\n",
    "            \n",
    "#     return binary_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getThreshold(image):\n",
    "#     # image = (image * 255).astype('uint8')\n",
    "\n",
    "#     counts, _ = np.histogram(image, bins=256, range=(0, 256))\n",
    "    \n",
    "#     total_pixels = counts.sum()\n",
    "#     gray_levels = np.arange(256)\n",
    "#     Tinit = round((gray_levels * counts).sum() / total_pixels) \n",
    "    \n",
    "#     while True:\n",
    "#         lower_pixels = counts[:Tinit]\n",
    "#         upper_pixels = counts[Tinit:]\n",
    "        \n",
    "#         if lower_pixels.sum() == 0 or upper_pixels.sum() == 0:\n",
    "#             break\n",
    "\n",
    "#         lower_mean = (gray_levels[:Tinit] * lower_pixels).sum() / lower_pixels.sum()\n",
    "#         upper_mean = (gray_levels[Tinit:] * upper_pixels).sum() / upper_pixels.sum()\n",
    "\n",
    "#         new_threshold = round((lower_mean + upper_mean) / 2)\n",
    "        \n",
    "#         if new_threshold == Tinit:\n",
    "#             break\n",
    "        \n",
    "#         Tinit = new_threshold\n",
    "    \n",
    "#     binary_image = np.where(image < Tinit, 0, 255) # 0 is black, 255 is white\n",
    "#     return binary_image\n",
    "\n",
    "\n",
    "# def adaptive (image, NumberOfDivisions):\n",
    "#     new_image = np.array_split(image, NumberOfDivisions, axis=1)\n",
    "#     thresholded_images = []\n",
    "#     for imagee in new_image:\n",
    "#         threshold = getThreshold(imagee)\n",
    "#         thresholded_images.append(threshold)    \n",
    "    \n",
    "#     combined_image = np.block(thresholded_images)\n",
    "\n",
    "#     return combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Testing\n",
    "# def deskew(original_img):\n",
    "#     img = np.copy((original_img))\n",
    "#     # Canny\n",
    "#     imgCanny = sk.feature.canny(img, sigma=1.5)\n",
    "#     thresh = sk.filters.threshold_otsu(imgCanny)\n",
    "#     imgCanny = (imgCanny >= thresh)\n",
    "\n",
    "#     # Apply Hough Transform\n",
    "#     # Generates a list of 360 Radian degrees (-pi/2, pi/2)\n",
    "#     angleSet = np.linspace(-np.pi, np.pi, 1440)\n",
    "#     houghArr, theta, dis = sk.transform.hough_line(imgCanny, angleSet)\n",
    "\n",
    "#     flatIdx = np.argmax(houghArr)\n",
    "#     bestTheta = (flatIdx % theta.shape[0])\n",
    "#     bestTheta = angleSet[bestTheta]\n",
    "#     bestDis = np.int32(np.floor(flatIdx / theta.shape[0]))\n",
    "#     bestDis = dis[bestDis]\n",
    "\n",
    "#     # Rotate\n",
    "#     thetaRotateDeg = (bestTheta*180)/np.pi\n",
    "#     if thetaRotateDeg > 0:\n",
    "#         thetaRotateDeg = thetaRotateDeg - 90\n",
    "#     else:\n",
    "#         thetaRotateDeg = thetaRotateDeg + 90\n",
    "\n",
    "#     imgRotated = (sk.transform.rotate(\n",
    "#         img, thetaRotateDeg, resize=True, mode='constant', cval=1))\n",
    "#     return imgRotated\n",
    "\n",
    "# def binarize(img, block_size=101):\n",
    "#     t = sk.filters.threshold_local(img, block_size, offset=10)\n",
    "#     img_b = img < t\n",
    "#     return img_b\n",
    "\n",
    "\n",
    "\n",
    "# def convertImgToUINT8(img_o):\n",
    "#     img = np.copy(img_o)\n",
    "#     img = img.astype(np.float64) / np.max(img)\n",
    "#     img = 255 * img\n",
    "#     img = img.astype(np.uint8)\n",
    "#     return img\n",
    "\n",
    "\n",
    "\n",
    "# img = io.imread(\"./images/image2.png\",as_gray=True)\n",
    "# if img.shape[0] > 1000 or img.shape[1] > 2000:\n",
    "#         img = sk.transform.resize(img, (img.shape[0]//4, img.shape[1]//4))\n",
    "# img1=deskew(img)\n",
    "# img2 = convertImgToUINT8(img1)\n",
    "# img3=binarize(img2)\n",
    "# show_images([img3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = io.imread(\"./images/image.png\",as_gray=True)\n",
    "# print(img.shape)\n",
    "# # 1. Binarization\n",
    "\n",
    "# # # Compute Otsu's threshold\n",
    "# # otsu_threshold = threshold_otsu(img)\n",
    "# # binary_image_ski = img > otsu_threshold\n",
    "\n",
    "# #Adaptive ski\n",
    "# # # Compute a local threshold\n",
    "# # block_size = 201  # Size of the local region to consider\n",
    "# # local_thresh = threshold_local(img, block_size, offset=0)\n",
    "\n",
    "# #our threshold\n",
    "# # print(img)\n",
    "# # threshold=getThreshold(img)\n",
    "# # img[img>threshold]=1\n",
    "# # img[img<=threshold]=0\n",
    "\n",
    "# show_images([img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_binarization(input_image):\n",
    "    # Calculate the histogram of the input image\n",
    "    hist = cv2.calcHist([input_image], [0], None, [256], [0, 256])\n",
    "    # Normalize the histogram for easier analysis\n",
    "    normalized_hist = hist / hist.sum()\n",
    "    \n",
    "    # Check if the histogram has significant peaks near 0 and 255\n",
    "    near_zero = normalized_hist[:20].sum()  # Sum of bins near 0\n",
    "    near_255 = normalized_hist[-20:].sum()  # Sum of bins near 255\n",
    "\n",
    "    # Thresholds for determining scanned images\n",
    "    if near_zero+near_255 > 0.75:\n",
    "        # Use Otsu's binarization for scanned images\n",
    "        _, binarized_image = cv2.threshold(input_image, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    else:\n",
    "        # Apply both Otsu and Adaptive Thresholding\n",
    "        _, otsu_binary = cv2.threshold(input_image, 0, 255,cv2.THRESH_BINARY+ cv2.THRESH_OTSU)\n",
    "        adaptive_binary = cv2.adaptiveThreshold(input_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                                cv2.THRESH_BINARY, blockSize=9, C=5)\n",
    "        \n",
    "        # Calculate the number of black pixels for Otsu's output\n",
    "        otsu_black_pixels = np.sum(otsu_binary == 0)\n",
    "\n",
    "        # Threshold for deciding noise\n",
    "        noise_threshold = np.sum(hist[:120])\n",
    "\n",
    "        if otsu_black_pixels > noise_threshold:\n",
    "            # Otsu produces noise, use Adaptive Thresholding\n",
    "            binarized_image = adaptive_binary\n",
    "        else:\n",
    "            # Otsu works fine\n",
    "            binarized_image = otsu_binary\n",
    "\n",
    "    return binarized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resize_with_aspect_ratio(image, target_width, target_height, color=0):\n",
    "    # Get original dimensions\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # Calculate the scaling factor to maintain aspect ratio\n",
    "    scale = min(target_width / w, target_height / h)\n",
    "    \n",
    "    # Compute the new dimensions\n",
    "    new_width = int(w * scale)\n",
    "    new_height = int(h * scale)\n",
    "    \n",
    "    # Resize the image\n",
    "    resized_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Create a new blank image with the target dimensions\n",
    "    canvas =np.full((target_height, target_width), color, dtype=np.uint8)\n",
    "    \n",
    "    # Calculate padding to center the resized image\n",
    "    x_offset = (target_width - new_width) // 2\n",
    "    y_offset = (target_height - new_height) // 2\n",
    "    \n",
    "    # Place the resized image onto the canvas\n",
    "    canvas[y_offset:y_offset + new_height, x_offset:x_offset + new_width] = resized_image\n",
    "    \n",
    "    return canvas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_image (binarized_image,lines):\n",
    "    rotated_image= binarized_image\n",
    "    if lines is not None:  # Found lines\n",
    "        angles = []  # Store the angles of the detected lines\n",
    "        zero_angle_count = 0  # Count lines with angles close to 0°\n",
    "        tolerance_zero = 2.0  # Tolerance to consider an angle as 0° (degrees)\n",
    "\n",
    "        for line in lines:\n",
    "            rho, theta = line[0]\n",
    "            # Convert polar coordinates to Cartesian line endpoints\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a * rho\n",
    "            y0 = b * rho\n",
    "            x1 = int(x0 + 1000 * (-b))  # Endpoint 1\n",
    "            y1 = int(y0 + 1000 * (a))\n",
    "            x2 = int(x0 - 1000 * (-b))  # Endpoint 2\n",
    "            y2 = int(y0 - 1000 * (a))\n",
    "\n",
    "            # # Draw the line on the output image\n",
    "            # cv2.line(output_image, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red line with thickness 2\n",
    "\n",
    "            # Convert angle to degrees\n",
    "            angle_degrees = 180 * theta / np.pi\n",
    "            angles.append(angle_degrees)\n",
    "\n",
    "            # Check if angle is close to 0° (horizontal line)\n",
    "            if abs(angle_degrees) < tolerance_zero or abs(angle_degrees - 180) < tolerance_zero:\n",
    "                zero_angle_count += 1\n",
    "\n",
    "        # Majority Check: If most lines are at zero angles, skip rotation\n",
    "        if zero_angle_count > len(angles) / 2:  # Majority condition\n",
    "            print(\"Majority of lines are horizontal. Skipping rotation.\")\n",
    "        else:\n",
    "            # Calculate the average angle excluding near-zero angles\n",
    "            # average_angle = np.mean([angle for angle in angles if abs(angle) > tolerance_zero])\n",
    "            mode_angle, _ = mode([angle for angle in angles if abs(angle) > tolerance_zero], axis= 0)\n",
    "            print(\"mode result\", mode_angle)\n",
    "            if abs(mode_angle)>2:\n",
    "                rotated_image = rotate(rotated_image, mode_angle - 90, cval=255)\n",
    "\n",
    "    else:\n",
    "        print(\"No lines found\")\n",
    "\n",
    "    return rotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bool_reverse(image):\n",
    "    image=255-image\n",
    "    image=image>0\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBoundedBoxes(image):\n",
    "    \"\"\"\n",
    "    Detects bounding boxes for staves in a binary image and returns binary images of the staves.\n",
    "    \"\"\"\n",
    "    img_height = image.shape[0]\n",
    "    img_width = image.shape[1]\n",
    "    max_dim = max(img_height,img_width)\n",
    "    print(\"max_dim\",max_dim)\n",
    "\n",
    "\n",
    "    # print(\"image entring remove small\" ,image)\n",
    "    closing = remove_small_objects(image, 2000, connectivity=8)\n",
    "    # print(\"after removing \", closing)\n",
    "\n",
    "    # Dilate vertically to connect staff lines\n",
    "    closing = binary_dilation(closing, footprint=np.ones((int(max_dim/40), 1)))\n",
    "    # print(\"image sfter dilation\",closing)\n",
    "    # Remove small objects to clean up noise\n",
    "    \n",
    "\n",
    "    # Show intermediate results (optional, for debugging)\n",
    "    show_images([closing], ['Closing and Small Object Removal'])\n",
    "\n",
    "    # Crop a portion of the image to exclude the beginning\n",
    "    img_without_begin = closing[:, int(img_height * 0.2):img_height]\n",
    "    show_images([closing, img_without_begin], ['Original', 'Without Beginning'])\n",
    "\n",
    "    # Convert binary images to uint8 for contour detection\n",
    "    img_without_begin = (img_without_begin * 255).astype('uint8')\n",
    "    output_image = (image * 255).astype('uint8')\n",
    "\n",
    "    # Find contours in both cropped and original binary images\n",
    "    contours_without_begin, _ = cv2.findContours(img_without_begin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours_with_begin, _ = cv2.findContours(output_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Check if contours differ between the cropped and original images\n",
    "    staves = []\n",
    "    correct_contours = contours_with_begin\n",
    "    if len(contours_with_begin) != len(contours_without_begin):\n",
    "        correct_contours = contours_without_begin\n",
    "\n",
    "    # Extract bounding boxes and binary images for each stave\n",
    "    for contour in correct_contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        if h * 4 < w and h * 7 > w:  # Check if the bounding box is wide enough to be a stave\n",
    "            print(\"Stave Length: \", w, \"Stave Height: \", h)\n",
    "            start_x = x\n",
    "            end_x = img_width\n",
    "            if correct_contours is contours_without_begin:\n",
    "                start_x = 0\n",
    "            stave = image[y:y + h, start_x:end_x]  # Keep binary format (no color conversion)\n",
    "            staves.append(stave)\n",
    "            show_images([stave], [\"Stave\"])  # Visualize each stave (optional)\n",
    "\n",
    "    return staves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runs_of_ones_array(bits):\n",
    "    bounded = np.hstack(([0], bits, [0]))\n",
    "    difs = np.diff(bounded)\n",
    "    run_starts, = np.where(difs > 0)\n",
    "    run_ends, = np.where(difs < 0)\n",
    "    return run_ends - run_starts\n",
    "\n",
    "\n",
    "\n",
    "def verticalRunLength(img):\n",
    "    # white runs\n",
    "    arr = []\n",
    "    for i in range(0, img.shape[1]):\n",
    "        a = runs_of_ones_array(img[:, i])\n",
    "        for x in a:\n",
    "            arr.append(x)\n",
    "    counts = np.bincount(arr)\n",
    "    staff_height = np.argmax(counts)\n",
    "    # black runs\n",
    "    arr = []\n",
    "    for i in range(0, img.shape[1]):\n",
    "        a = runs_of_ones_array(np.invert(img[:, i]))\n",
    "        for x in a:\n",
    "            arr.append(x)\n",
    "    # print(arr)\n",
    "    counts = np.bincount(arr)\n",
    "    staff_space = np.argmax(counts)\n",
    "    return staff_height, staff_space\n",
    "\n",
    "def get_lines_rows(img, T_LEN):\n",
    "    row_start_freq = np.zeros((1, img.shape[0]+5))[0]\n",
    "    row_starts = []\n",
    "\n",
    "    for i in range(0, img.shape[1]):\n",
    "        arr = runs_of_ones_array(img[:, i])\n",
    "        k = 0\n",
    "        j = 0\n",
    "        while j < img.shape[0]:\n",
    "            if img[j][i] == True:\n",
    "                if arr[k] <= T_LEN + 2 and arr[k] >= T_LEN - 2:\n",
    "                    row_start_freq[j] += 1\n",
    "                    j += arr[k]-1\n",
    "                else:\n",
    "                    j += arr[k]\n",
    "\n",
    "                k += 1\n",
    "            j += 1\n",
    "\n",
    "    max_freq_row_start = 0\n",
    "    for r in row_start_freq:\n",
    "        max_freq_row_start = max(max_freq_row_start, r)\n",
    "\n",
    "    for i in range(len(row_start_freq)):\n",
    "        # Approximately, if the row \"i\" is frequently treated as a starting of staffs with this ratio\n",
    "        # by the most frequnt starting row, then consider it as a starting row of staffs.\n",
    "        if row_start_freq[i]/max_freq_row_start >= 0.12:\n",
    "            row_starts.append(i)\n",
    "    return [row_starts, row_start_freq, max_freq_row_start]\n",
    "\n",
    "def dilate_vertically_with_staff_space(stave, width, height):\n",
    "    # Ensure the stave is in uint8 format\n",
    "    if stave.dtype != np.uint8:\n",
    "        stave = (stave * 255).astype(np.uint8)  # Convert boolean to uint8 (255 for white, 0 for black)\n",
    "\n",
    "    # Create a vertical structuring element (kernel)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (width, height))\n",
    "\n",
    "    # Apply vertical dilation\n",
    "    dilated_stave = cv2.dilate(stave, kernel, iterations=1)\n",
    "\n",
    "    return dilated_stave\n",
    "\n",
    "def segment_staves(stave, original_stave,staff_space):    \n",
    "    # Ensure the stave is in uint8 format\n",
    "    if stave.dtype != np.uint8:\n",
    "        stave = (stave * 255).astype(np.uint8)\n",
    "\n",
    "    # Find contours of the dilated stave\n",
    "    contours, _ = cv2.findContours(stave, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Sort contours left to right (by x-coordinate)\n",
    "    contours = sorted(contours, key=lambda contour: cv2.boundingRect(contour)[0])\n",
    "\n",
    "    # Create a copy of the stave to draw contours on\n",
    "    stave_with_contours = cv2.cvtColor(stave, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # List to store extracted note images\n",
    "    notes = []\n",
    "\n",
    "    for contour in contours:\n",
    "        # Get the bounding rectangle (x, y, width, height) for each contour\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Draw the contour as a green rectangle on the stave copy\n",
    "        if h>staff_space*2:\n",
    "            cv2.rectangle(stave_with_contours, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            \n",
    "            # Extract the note from the original stave using the bounding box\n",
    "            note = original_stave[y:y+h, x:x+w]\n",
    "            notes.append(note)\n",
    "\n",
    "    # Show the stave with contours drawn\n",
    "    show_images([stave_with_contours], [\"Stave with Contours\"])\n",
    "\n",
    "    return notes\n",
    "\n",
    "def remove_staff_lines_columnwise(staves, staff_height):\n",
    "    processed_staves = []\n",
    "\n",
    "    for stave in staves:\n",
    "        # Copy the stave to modify\n",
    "        processed_stave = stave.copy()\n",
    "\n",
    "        # Loop through each column in the stave\n",
    "        for col in range(stave.shape[1]):\n",
    "            # Get the binary column data\n",
    "            column_data = stave[:, col]\n",
    "\n",
    "            # Run-length encode the column\n",
    "            run_lengths = runs_of_ones_array(column_data)\n",
    "\n",
    "            # Check if any gap (run of black pixels) is larger than the staff height\n",
    "            if any(run > staff_height*2 for run in run_lengths):\n",
    "                # Leave the column as is (it contains symbols or non-staff lines)\n",
    "                continue\n",
    "            else:\n",
    "                # Set the entire column to black (remove staff lines)\n",
    "                processed_stave[:, col] = 0\n",
    "\n",
    "        # Append the processed stave\n",
    "        processed_staves.append(processed_stave)\n",
    "\n",
    "    return processed_staves\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread(\"./testcases/10.jpg\")\n",
    "# img = cv2.imread(\"./images/image2.png\")\n",
    "show_images([img],[\"original image\"])\n",
    "\n",
    "#remove noise using ski and opencv filters\n",
    "remove_noise = cv2.bilateralFilter(img, 3, 75, 75)\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(remove_noise, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#dynamic_binarization to apply any of otsu or adaptive\n",
    "binarized_image=dynamic_binarization(gray)\n",
    "show_images([binarized_image],[\"binarized image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = cv2.Canny(gray, 50, 150)\n",
    "show_images([edges],[\"edges\"])\n",
    "\n",
    "\n",
    "#detect lines using Hough Transform\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180.0, 250, np.array([]))# show_images([lines],[\"lines\"])\n",
    "\n",
    "\n",
    "# Rotate the image based on the detected lines\n",
    "rotated_image = rotate_image(binarized_image,lines)\n",
    "show_images([rotated_image],[\"rotated_image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_image=convert_to_bool_reverse(rotated_image)\n",
    "show_images([final_image],[\"final_image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rotated_image_copy=rotated_image.copy()\n",
    "# #Remove small details\n",
    "# morphology_input=255-rotated_image\n",
    "# morphology_input=morphology_input>0\n",
    "# # closing=binary_erosion(morphology_input,footprint= np.ones((1, 5)))\n",
    "# dilation=binary_dilation(morphology_input, np.ones((5,1)))\n",
    "# dilation=remove_small_objects(dilation, 500, connectivity=8)\n",
    "# # print(dilation)\n",
    "\n",
    "\n",
    "# # Find contours of big bounding box all notes\n",
    "# # closing=binary_erosion(dilation,footprint= np.ones((1, 5)))\n",
    "# dilation=binary_dilation(dilation, np.ones((200,10)))\n",
    "# show_images([dilation],[ \"dilation\"])\n",
    "\n",
    "# contours_input= (dilation * 255).astype('uint8')\n",
    "# # show_images([contours_input],[\"contors\"])\n",
    "# # print(contours_input)\n",
    "# contours, _ = cv2.findContours(contours_input, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# # Create a copy of the original image to draw the bounding boxes\n",
    "# output_image = cv2.cvtColor(rotated_image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "\n",
    "# max_area = 0\n",
    "# max_bbox = None  # Will store the coordinates of the maximum bounding box\n",
    "# # Loop over the contours to get the bounding rectangles\n",
    "# for contour in contours:\n",
    "\n",
    "#     # Get the bounding rectangle (x, y, width, height)\n",
    "#     x, y, w, h = cv2.boundingRect(contour)\n",
    "#     cv2.rectangle(output_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "#     # Calculate the area of the bounding rectangle\n",
    "#     area = w * h\n",
    "#     # Check if this is the largest bounding box so far\n",
    "#     if area > max_area:\n",
    "#         max_area = area\n",
    "#         max_bbox = (x, y, w, h)\n",
    "# if max_bbox is not None:\n",
    "#     x, y, w, h = max_bbox\n",
    "#     print(\"maxx\")\n",
    "#     cv2.rectangle(output_image, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\n",
    "# # Display the result with bounding boxes\n",
    "# # cv2.imshow('Bounding Rectangles', output_image)\n",
    "# # cv2.waitKey(0)\n",
    "# # cv2.destroyAllWindows()\n",
    "# show_images([output_image],[\"output_image\"])\n",
    "\n",
    "\n",
    "# # x, y, w, h = max_bbox\n",
    "# # cropped_image = rotated_image_copy[y:y+h, x:x+w]\n",
    "# # show_images([cropped_image],[\"cropped_image1\"])\n",
    "\n",
    "# # cropped_image=255-cropped_image\n",
    "# # cropped_image=cropped_image>0\n",
    "# final_image=remove_small_objects(output_image, 700, connectivity=8)\n",
    "\n",
    "# show_images([final_image],[\"final_image\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAVE EXTRACTION\n",
    "1. Apply run length encoding to get staff height and staff space\n",
    "2. dilate with staff space\n",
    "3. apply countours\n",
    "4. extract these countours\n",
    "5. loop on staves and remove staff lines around notes\n",
    "6. dilate the rest of notes\n",
    "7. apply contours on each stave to get single notes \n",
    "8. Further process each single note and remove small objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#staves using contoursxx\n",
    "staves=getBoundedBoxes(final_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, stave in enumerate(staves):\n",
    "    show_images([stave], [f\"Stave {i}\"])\n",
    "    \n",
    "    #Get staff_height, staff_sapce\n",
    "    staff_height,staff_space = verticalRunLength(stave)\n",
    "    print(\"staff_height\",staff_height)\n",
    "    print(\"staff_space\",staff_space)\n",
    "\n",
    "    \n",
    "\n",
    "#Remove Staff line using runlength encoding\n",
    "processed_staves = remove_staff_lines_columnwise(staves, staff_height)\n",
    "\n",
    "\n",
    "# Show the processed staves\n",
    "for i, stave in enumerate(processed_staves):\n",
    "    show_images([stave], [f\"Processed Stave {i}\"])\n",
    "    \n",
    "#Use dilation again to sengment notes from staves after staff lines removal\n",
    "dilated_staves=[]\n",
    "for i in range(len(processed_staves)):\n",
    "    dilated_stave = dilate_vertically_with_staff_space(processed_staves[i], staff_height * 3, staff_space + staff_height)\n",
    "    dilated_staves.append(dilated_stave)\n",
    "\n",
    "show_images(dilated_staves)\n",
    "\n",
    "#Get notes from the staves using contours\n",
    "notes=[]\n",
    "for i in range(len(dilated_staves)):\n",
    "    notes.append(segment_staves(dilated_staves[i], processed_staves[i],staff_space))    \n",
    "\n",
    "for i, note in enumerate(notes):\n",
    "    show_images(note)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_remaining_staff_notes(note, staff_height):\n",
    "    processed_note = note.copy()\n",
    "    rows, cols = note.shape\n",
    "\n",
    "    for col in range(cols):\n",
    "        column_data = note[:, col]\n",
    "\n",
    "        bounded = np.hstack(([0], column_data, [0]))\n",
    "        difs = np.diff(bounded)\n",
    "        run_starts, = np.where(difs > 0)\n",
    "        run_ends, = np.where(difs < 0)\n",
    "\n",
    "        for i in range(len(run_starts)):\n",
    "            run_start = run_starts[i]\n",
    "            run_end = run_ends[i]\n",
    "            run_length = run_end - run_start\n",
    "\n",
    "\n",
    "            # Check if the run length is approximately equal to the staff height, the aproximation is based on the staff height\n",
    "            if run_length <= staff_height*2: # check in bigger images ----------------->\n",
    "                # if column_data[run_start - staff_height] == 0 and column_data[run_end +  (staff_height if (run_end + staff_height) < len(column_data))] == 0: \n",
    "                if (run_start - staff_height >= 0 and column_data[run_start - staff_height] == 0) and (run_end + staff_height < len(column_data) and column_data[run_end + staff_height] == 0):\n",
    "                    processed_note[run_start : run_end , col] = 0\n",
    "\n",
    "    return processed_note"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process each note to remove small lines remaining\n",
    "for i,note in enumerate(notes):\n",
    "    for j,notaia in enumerate(note):\n",
    "        cleaned_note =remove_remaining_staff_notes(notaia, staff_height)\n",
    "        notes[i][j]=dilate_vertically_with_staff_space(cleaned_note,1,staff_height)\n",
    "\n",
    "for i,note in enumerate(notes):\n",
    "    show_images(note)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rows in staves using voting mechanism with run length encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines_rows(img, T_LEN):\n",
    "    row_start_freq = np.zeros((1, img.shape[0]+5))[0]\n",
    "    row_starts = []\n",
    "\n",
    "    for i in range(0, img.shape[1]):\n",
    "        arr = runs_of_ones_array(img[:, i])\n",
    "        k = 0\n",
    "        j = 0\n",
    "        while j < img.shape[0]:\n",
    "            if img[j][i] == True:\n",
    "                if arr[k] <= T_LEN + 2 and arr[k] >= T_LEN - 2:\n",
    "                    row_start_freq[j] += 1\n",
    "                    j += arr[k]-1\n",
    "                else:\n",
    "                    j += arr[k]\n",
    "\n",
    "                k += 1\n",
    "            j += 1\n",
    "\n",
    "    max_freq_row_start = 0\n",
    "    for r in row_start_freq:\n",
    "        max_freq_row_start = max(max_freq_row_start, r)\n",
    "\n",
    "    for i in range(len(row_start_freq)):\n",
    "        # Approximately, if the row \"i\" is frequently treated as a starting of staffs with this ratio\n",
    "        # by the most frequnt starting row, then consider it as a starting row of staffs.\n",
    "        if row_start_freq[i]/max_freq_row_start >= 0.12:\n",
    "            row_starts.append(i)\n",
    "    return [row_starts, row_start_freq, max_freq_row_start]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_notes(cleaned_stave, staff_lines, staff_space,staff_height):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (staff_space, staff_space)) # it get affected by the zoom in factor,range [(3,3) - (20,20)] ------> \n",
    "    processed_stave = cv2.morphologyEx(cleaned_stave.astype('uint8') * 255, cv2.MORPH_CLOSE, kernel)\n",
    "    processed_stave = cv2.morphologyEx(processed_stave.astype('uint8') * 255, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Optional: Edge detection to highlight contours\n",
    "    edges = cv2.Canny((processed_stave * 255).astype('uint8'), 50, 150)\n",
    "    show_images([edges], ['Edges'])\n",
    "\n",
    "    # Step 3: Find contours\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    show_images([cv2.drawContours(processed_stave, contours, -1, (0, 255, 0), 2)], ['Contours'])\n",
    "\n",
    "    contours = sorted(contours, key=lambda contour: cv2.boundingRect(contour)[0])\n",
    "\n",
    "    notes = []\n",
    "\n",
    "    differences = [j - i for i, j in zip(staff_lines[:-1], staff_lines[1:])]\n",
    "    average_distance_between_spaces = sum(differences) / len(differences)\n",
    "    print(\"average dist: \" + str(average_distance_between_spaces))\n",
    "    \n",
    "    staff_lines.append(staff_lines[-1]+int(average_distance_between_spaces))\n",
    "    staff_lines.append(staff_lines[0]-int(average_distance_between_spaces))\n",
    "\n",
    "    staff_lines = sorted(staff_lines)\n",
    "\n",
    "    print(staff_lines)\n",
    "    notes=[]\n",
    "    for contour in contours:\n",
    "        # Filter based on contour size (area) and aspect ratio\n",
    "        area = cv2.contourArea(contour)\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        aspect_ratio = w / h if h > 0 else 0\n",
    "\n",
    "        # factor = 12 # this factor is for the value of zoom in\n",
    "        print(\"area: \" + str(area) + \", aspect ratio: \" + str(aspect_ratio))\n",
    "        if (staff_space * (1/2)) <= area <= (staff_space*(3/2)):  # Typical note head properties  area varies with the zoom in, range [300] --------->\n",
    "            note_center = y + h // 2  # Vertical center of the note head\n",
    "\n",
    "            print(\"note center: \" + str(note_center) + \",x= \" + str(x) + \",y1= \" + str(y) +\",y2= \" + str(y+h))\n",
    "\n",
    "            note_names_treble = ['C','D','E','F','G','A','B','C2','D2','E2','F2','G2','A2','B2']\n",
    "            y1=y + int(average_distance_between_spaces/ 8)\n",
    "            y2=y+h - int(average_distance_between_spaces/ 8)\n",
    "\n",
    "            if  y2>staff_lines[-1] and y1<staff_lines[-1]:\n",
    "                notes.append('C')\n",
    "            elif y2<=staff_lines[-1] and y1>=staff_lines[-2]:\n",
    "                notes.append('D')\n",
    "            elif y2>staff_lines[-2] and y1<staff_lines[-2]:\n",
    "                notes.append('E')\n",
    "            elif y2<=staff_lines[-2] and y1>=staff_lines[-3]:\n",
    "                notes.append('F')\n",
    "            elif y2>staff_lines[-3] and y1<staff_lines[-3]:\n",
    "                notes.append('G')\n",
    "            elif y2<=staff_lines[-3] and y1>=staff_lines[-4]:\n",
    "                notes.append('A')\n",
    "            elif y2>staff_lines[-4] and y1<staff_lines[-4]:\n",
    "                notes.append('B')\n",
    "            elif y2<=staff_lines[-4] and y1>=staff_lines[-5]:\n",
    "                notes.append('C2')\n",
    "            elif y2>staff_lines[-5] and y1<staff_lines[-5]:\n",
    "                notes.append('D2')\n",
    "            elif y2<=staff_lines[-5] and y1>=staff_lines[-6]:\n",
    "                notes.append('E2')\n",
    "            elif y2>staff_lines[-6] and y1<staff_lines[-6]:\n",
    "                notes.append('F2')\n",
    "            elif y2<=staff_lines[-6] and y1>=staff_lines[-7]:\n",
    "                notes.append('A2')\n",
    "            elif y2>staff_lines[-7] and y1<staff_lines[-7]:\n",
    "                notes.append('B2')\n",
    "    return notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stave in staves:\n",
    "    rows=get_lines_rows(stave,staff_height)\n",
    "    print(rows[0])\n",
    "    detected_notes=detect_notes(stave,rows[0],staff_space,staff_height)\n",
    "    print(detected_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segment stave into notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def segment_staves(stave, original_stave,staff_space):    \n",
    "#     \"\"\"\n",
    "#     Segments the musical notes from the stave by finding contours, drawing them, \n",
    "#     and extracting the notes as individual images.\n",
    "    \n",
    "#     Parameters:\n",
    "#         stave (np.array): Binary processed stave image.\n",
    "#         original_stave (np.array): Original stave image (grayscale or binary) to extract notes.\n",
    "        \n",
    "#     Returns:\n",
    "#         list: A list of extracted musical note images.\n",
    "#     \"\"\"\n",
    "#     # Ensure the stave is in uint8 format\n",
    "#     if stave.dtype != np.uint8:\n",
    "#         stave = (stave * 255).astype(np.uint8)\n",
    "\n",
    "#     # Find contours of the dilated stave\n",
    "#     contours, _ = cv2.findContours(stave, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#     # Sort contours left to right (by x-coordinate)\n",
    "#     contours = sorted(contours, key=lambda contour: cv2.boundingRect(contour)[0])\n",
    "\n",
    "#     # Create a copy of the stave to draw contours on\n",
    "#     stave_with_contours = cv2.cvtColor(stave, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "#     # List to store extracted note images\n",
    "#     notes = []\n",
    "\n",
    "#     for contour in contours:\n",
    "#         # Get the bounding rectangle (x, y, width, height) for each contour\n",
    "#         x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "#         # Draw the contour as a green rectangle on the stave copy\n",
    "#         if h>staff_space*2:\n",
    "#             cv2.rectangle(stave_with_contours, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            \n",
    "#             # Extract the note from the original stave using the bounding box\n",
    "#             note = original_stave[y:y+h, x:x+w]\n",
    "#             notes.append(note)\n",
    "\n",
    "#     # Show the stave with contours drawn\n",
    "#     show_images([stave_with_contours], [\"Stave with Contours\"])\n",
    "\n",
    "#     return notes\n",
    "\n",
    "\n",
    "# def dilate_vertically_with_staff_space(stave, width, height):\n",
    "#     \"\"\"\n",
    "#     Dilates the given stave vertically with a kernel size based on the staff space.\n",
    "    \n",
    "#     Parameters:\n",
    "#         stave (np.array): Binary image of the stave.\n",
    "#         staff_space (int): The space between staff lines, used for vertical dilation.\n",
    "#         staff_height (int): The height of the staff lines.\n",
    "        \n",
    "#     Returns:\n",
    "#         np.array: The vertically dilated stave.\n",
    "#     \"\"\"\n",
    "#     # Ensure the stave is in uint8 format\n",
    "#     if stave.dtype != np.uint8:\n",
    "#         stave = (stave * 255).astype(np.uint8)  # Convert boolean to uint8 (255 for white, 0 for black)\n",
    "\n",
    "#     # Create a vertical structuring element (kernel)\n",
    "#     kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (width, height))\n",
    "\n",
    "#     # Apply vertical dilation\n",
    "#     dilated_stave = cv2.dilate(stave, kernel, iterations=1)\n",
    "\n",
    "#     return dilated_stave\n",
    "\n",
    "\n",
    "# # Apply vertical dilation to the first processed stave\n",
    "# # dilated_stave = dilate_vertically_with_staff_space(processed_staves[0], staff_space, staff_space + staff_height)\n",
    "# dilated_staves=[]\n",
    "# for i in range(len(processed_staves)):\n",
    "#     dilated_stave = dilate_vertically_with_staff_space(processed_staves[i], staff_height * 3, staff_space + staff_height)\n",
    "#     dilated_staves.append(dilated_stave)\n",
    "\n",
    "# show_images(dilated_staves)\n",
    "\n",
    "# notes=[]\n",
    "# for i in range(len(dilated_staves)):\n",
    "#     notes.append(segment_staves(dilated_staves[i], processed_staves[i],staff_space))    \n",
    "\n",
    "# for i, note in enumerate(notes):\n",
    "#     show_images(note)\n",
    "# # # Show the original and dilated staves\n",
    "# # show_images([processed_staves[0], dilated_stave], [\"Original Processed Stave\", \"Vertically Dilated Stave\"])\n",
    "\n",
    "# # Segment the staves and extract musical notes\n",
    "# # notes = segment_staves(dilated_stave, processed_staves[0])\n",
    "\n",
    "# # Show each extracted note\n",
    "# # for i, note in enumerate(notes):\n",
    "# #     show_images([note], [f\"Note {i+1}\"])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove_staff_lines_columnwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_remaining_staff_notes(note, staff_height):\n",
    "#     \"\"\"\n",
    "#     Removes staff lines from note by analyzing each column's run lengths.\n",
    "#     If a column has a run of white pixels equal to the staff height, \n",
    "#     and the above and below columns have black runs, then this column is considered a staff line and removed.\n",
    "\n",
    "#     Parameters:\n",
    "#         note (np.array): Binary image of the note (white = 1, black = 0).\n",
    "#         staff_height (int): The detected height of the staff lines.\n",
    "\n",
    "#     Returns:\n",
    "#         np.array: The processed note with staff lines removed.\n",
    "#     \"\"\"\n",
    "#     processed_note = note.copy()\n",
    "#     rows, cols = note.shape\n",
    "\n",
    "#     for col in range(cols):\n",
    "#         column_data = note[:, col]\n",
    "\n",
    "#         bounded = np.hstack(([0], column_data, [0]))\n",
    "#         difs = np.diff(bounded)\n",
    "#         run_starts, = np.where(difs > 0)\n",
    "#         run_ends, = np.where(difs < 0)\n",
    "\n",
    "#         for i in range(len(run_starts)):\n",
    "#             run_start = run_starts[i]\n",
    "#             run_end = run_ends[i]\n",
    "#             run_length = run_end - run_start\n",
    "\n",
    "\n",
    "#             # Check if the run length is approximately equal to the staff height, the aproximation is based on the staff height\n",
    "#             if run_length <= staff_height*2: # chcek in bigger images ----------------->\n",
    "#                 # if column_data[run_start - staff_height] == 0 and column_data[run_end +  (staff_height if (run_end + staff_height) < len(column_data))] == 0: \n",
    "#                 if (run_start - staff_height >= 0 and column_data[run_start - staff_height] == 0) and (run_end + staff_height < len(column_data) and column_data[run_end + staff_height] == 0):\n",
    "#                     processed_note[run_start : run_end , col] = 0\n",
    "\n",
    "#     return processed_note\n",
    "\n",
    "# for i,note in enumerate(notes):\n",
    "#     for j,notaia in enumerate(note):\n",
    "#         notes[i][j] =remove_remaining_staff_notes(notaia, staff_height)\n",
    "\n",
    "# for i,note in enumerate(notes):\n",
    "#     show_images(note)\n",
    "# # Process a sample note from the extracted notes\n",
    "# # processed_note = remove_remaining_staff_notes(notes[8], staff_height)\n",
    "# # # processed_note= dilate_vertically_with_staff_space(processed_note, 1, staff_height)\n",
    "\n",
    "# # # Show the original and processed notes\n",
    "# # show_images([notes[8], processed_note], [\"Original Note\", \"Processed Note\",])\n",
    "\n",
    "# # # Process a sample note from the extracted notes\n",
    "# # processed_note = remove_remaining_staff_notes(notes[18], staff_height)\n",
    "# # # processed_note= dilate_vertically_with_staff_space(processed_note, 1, staff_height * 2)\n",
    "\n",
    "\n",
    "# # # Show the original and processed notes\n",
    "# # show_images([notes[18], processed_note,], [\"Original Note\", \"Processed Note\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to detect bounding boxes for staves\n",
    "\n",
    "# def getBoundedBoxes(image):\n",
    "#     #get staff bounding boxes whether they are connected or not\n",
    "#     img_height=image.shape[0]\n",
    "#     img_width=image.shape[1]\n",
    "\n",
    "#     dilation = binary_dilation(image, footprint=np.ones((10, 1)))\n",
    "#     # show_images([dilation], ['Dilation'])\n",
    "\n",
    "#     closing = remove_small_objects(dilation, 200, connectivity=8)\n",
    "#     show_images([closing], ['Closing and Small Object Removal'])\n",
    "\n",
    "\n",
    "#     img_without_begin=closing[:,int(img_height*0.2):img_height]\n",
    "#     show_images([closing,img_without_begin])\n",
    "\n",
    "#     img_without_begin = (img_without_begin * 255).astype('uint8')\n",
    "#     output_image = (image * 255).astype('uint8')\n",
    "\n",
    "\n",
    "#     contours_without_begin, _ = cv2.findContours(img_without_begin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     contours_with_begin, _ = cv2.findContours(output_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#     img_without_begin = cv2.cvtColor(img_without_begin, cv2.COLOR_GRAY2BGR)\n",
    "#     output_image = cv2.cvtColor(output_image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "#     #check if they are connected in the begining\n",
    "#     staves=[]\n",
    "#     correct_countours=contours_with_begin\n",
    "#     is_correct_contours=False\n",
    "\n",
    "#     if len(contours_with_begin) != len(contours_without_begin):\n",
    "#         is_correct_contours=True\n",
    "#         correct_countours=contours_without_begin\n",
    "        \n",
    "#     for contour in correct_countours:\n",
    "#         x, y, w, h = cv2.boundingRect(contour)\n",
    "#         # cv2.rectangle(output_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "#         if(w>1.1*h and w*h > 50):\n",
    "#             start_x = x\n",
    "#             end_x = img_width\n",
    "#             # print(\"width\",img_width)\n",
    "#             # print(\"final_image shape\",image.shape)\n",
    "#             if(is_correct_contours):\n",
    "#                 start_x=0\n",
    "#             stave = output_image[y:y + h, start_x:end_x]\n",
    "#             # print(\"Width\",w)\n",
    "#             # print(\"Height\",h)\n",
    "#             staves.append(stave)\n",
    "#             show_images([stave], [\"Stave222\"])\n",
    "\n",
    "#     return staves\n",
    "\n",
    "# staves2= getBoundedBoxes(final_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_staff_lines(staves):\n",
    "#     cleaned_staves = []\n",
    "#     staff_lines_positions = []\n",
    "\n",
    "#     for stave in staves:\n",
    "#         # Invert stave to make lines white on black background\n",
    "#         stave = 255 - stave\n",
    "        \n",
    "#         # Edge detection for the stave\n",
    "#         edges = cv2.Canny(stave, 50, 150, apertureSize=3)\n",
    "#         show_images([edges], ['Edges'])\n",
    "\n",
    "#         # Detect lines using Hough Transform\n",
    "#         lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=50, maxLineGap=10)\n",
    "        \n",
    "#         if lines is not None:\n",
    "#             line_y_positions = []\n",
    "#             for line in lines:\n",
    "#                 x1, y1, x2, y2 = line[0]\n",
    "#                 if abs(y2 - y1) < 5:  # Ensure the line is horizontal\n",
    "#                     line_y_positions.append((y1 + y2) // 2)  # Average y-coordinate for the line\n",
    "\n",
    "#             # Get 5 staff line positions by finding the most frequent y-coordinates\n",
    "#             line_y_positions = sorted(line_y_positions)\n",
    "#             staff_lines = []\n",
    "#             for y in line_y_positions:\n",
    "#                 if not staff_lines or abs(y - staff_lines[-1]) > 5:  # Avoid duplicates\n",
    "#                     staff_lines.append(y)\n",
    "#             staff_lines_positions.append(staff_lines[:5])  # Ensure only 5 lines are kept\n",
    "#         else:\n",
    "#             staff_lines_positions.append([])  # No lines detected\n",
    "\n",
    "#         stave_ratio = stave.shape[1]/stave.shape[0]\n",
    "#         print(\"Stave ratio: \"+str(stave_ratio))\n",
    "\n",
    "\n",
    "#         # Remove the detected staff lines from the stave image\n",
    "#         horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (100, 1)) # x value of MORPH_RECT range [15-100] it depend on the zoom in of ------>\n",
    "#         detected_lines = cv2.morphologyEx(stave, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        \n",
    "#         show_images([detected_lines])\n",
    "\n",
    "#         cleaned_image = stave - detected_lines\n",
    "#         cleaned_image = cleaned_image > 0\n",
    "#         dilated = binary_dilation(cleaned_image, footprint=np.ones((8, 1))) # 1st dilation depeneds on the zoom in , range [2-7] ------>\n",
    "\n",
    "#         cleaned_staves.append(dilated)\n",
    "#         # show_images([dilated], ['Cleaned Stave'])\n",
    "\n",
    "#     return cleaned_staves, staff_lines_positions\n",
    "\n",
    "# cleaned_staves, staff_lines_positions = remove_staff_lines(staves)\n",
    "# show_images(cleaned_staves)\n",
    "# print(staff_lines_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def detect_notes(cleaned_stave, staff_lines):\n",
    "#     # Step 1: Remove staff lines\n",
    "#     # stave_no_lines = cleaned_stave.copy()\n",
    "#     # for line in staff_lines:\n",
    "#     #     stave_no_lines[line - 2:line + 2, :] = 0  # Mask out staff lines (2-pixel width)\n",
    "#     # Step 2: Use morphological operations to isolate note heads\n",
    "\n",
    "#     kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (25, 25)) # it get affected by the zoom in factor,range [(3,3) - (20,20)] ------> \n",
    "#     processed_stave = cv2.morphologyEx(cleaned_stave.astype('uint8') * 255, cv2.MORPH_CLOSE, kernel)\n",
    "#     processed_stave = cv2.morphologyEx(processed_stave.astype('uint8') * 255, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "#     # Optional: Edge detection to highlight contours\n",
    "#     edges = cv2.Canny((processed_stave * 255).astype('uint8'), 50, 150)\n",
    "#     show_images([edges], ['Edges'])\n",
    "\n",
    "#     # Step 3: Find contours\n",
    "#     contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     show_images([cv2.drawContours(processed_stave, contours, -1, (0, 255, 0), 2)], ['Contours'])\n",
    "\n",
    "#     contours = sorted(contours, key=lambda contour: cv2.boundingRect(contour)[0])\n",
    "\n",
    "#     notes = []\n",
    "\n",
    "#     differences = [j - i for i, j in zip(staff_lines[:-1], staff_lines[1:])]\n",
    "#     average_distance_between_spaces = sum(differences) / len(differences)\n",
    "#     print(\"average dist: \" + str(average_distance_between_spaces))\n",
    "    \n",
    "#     staff_lines.append(staff_lines[-1]+int(average_distance_between_spaces))\n",
    "#     staff_lines.append(staff_lines[0]-int(average_distance_between_spaces))\n",
    "\n",
    "#     staff_lines = sorted(staff_lines)\n",
    "\n",
    "#     print(staff_lines)\n",
    "#     notes=[]\n",
    "#     for contour in contours:\n",
    "#         # Filter based on contour size (area) and aspect ratio\n",
    "#         area = cv2.contourArea(contour)\n",
    "#         x, y, w, h = cv2.boundingRect(contour)\n",
    "#         aspect_ratio = w / h if h > 0 else 0\n",
    "\n",
    "#         factor = 12 # this factor is for the value of zoom in\n",
    "#         print(\"area: \" + str(area) + \", aspect ratio: \" + str(aspect_ratio))\n",
    "#         if (10 * factor) < area < (300 * factor) and 0.7 < aspect_ratio < 1.3:  # Typical note head properties  area varies with the zoom in, range [300] --------->\n",
    "#             note_center = y + h // 2  # Vertical center of the note head\n",
    "\n",
    "#             print(\"note center: \" + str(note_center) + \",x= \" + str(x) + \",y1= \" + str(y) +\",y2= \" + str(y+h))\n",
    "\n",
    "#             note_names_treble = ['C','D','E','F','G','A','B','C2','D2','E2','F2','G2','A2','B2']\n",
    "#             y1=y + int(average_distance_between_spaces/ 8)\n",
    "#             y2=y+h - int(average_distance_between_spaces/ 8)\n",
    "\n",
    "#             if  y2>staff_lines[-1] and y1<staff_lines[-1]:\n",
    "#                 notes.append('C')\n",
    "#             elif y2<=staff_lines[-1] and y1>=staff_lines[-2]:\n",
    "#                 notes.append('D')\n",
    "#             elif y2>staff_lines[-2] and y1<staff_lines[-2]:\n",
    "#                 notes.append('E')\n",
    "#             elif y2<=staff_lines[-2] and y1>=staff_lines[-3]:\n",
    "#                 notes.append('F')\n",
    "#             elif y2>staff_lines[-3] and y1<staff_lines[-3]:\n",
    "#                 notes.append('G')\n",
    "#             elif y2<=staff_lines[-3] and y1>=staff_lines[-4]:\n",
    "#                 notes.append('A')\n",
    "#             elif y2>staff_lines[-4] and y1<staff_lines[-4]:\n",
    "#                 notes.append('B')\n",
    "#             elif y2<=staff_lines[-4] and y1>=staff_lines[-5]:\n",
    "#                 notes.append('C2')\n",
    "#             elif y2>staff_lines[-5] and y1<staff_lines[-5]:\n",
    "#                 notes.append('D2')\n",
    "#             elif y2<=staff_lines[-5] and y1>=staff_lines[-6]:\n",
    "#                 notes.append('E2')\n",
    "#             elif y2>staff_lines[-6] and y1<staff_lines[-6]:\n",
    "#                 notes.append('F2')\n",
    "#             elif y2<=staff_lines[-6] and y1>=staff_lines[-7]:\n",
    "#                 notes.append('A2')\n",
    "#             elif y2>staff_lines[-7] and y1<staff_lines[-7]:\n",
    "#                 notes.append('B2')\n",
    "\n",
    "    \n",
    "#     return notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to map note positions to musical notes\n",
    "# def map_positions_to_notes(positions, clef='treble'):\n",
    "#     note_names_treble = ['F', 'E', 'D', 'C', 'B', 'A', 'G']\n",
    "#     note_names_bass = ['A', 'G', 'F', 'E', 'D', 'C', 'B']\n",
    "    \n",
    "#     note_names = note_names_treble if clef == 'treble' else note_names_bass\n",
    "#     mapped_notes = [note_names[pos % len(note_names)] for pos in positions if pos >= 0]\n",
    "#     return mapped_notes\n",
    "\n",
    "# # Main processing\n",
    "# # final_image = cv2.imread('sheet_music.png', cv2.IMREAD_GRAYSCALE)  # Load your image here\n",
    "# # final_image = final_image < 128  # Binarize the image\n",
    "# # show_images([final_image], [\"Final Image\"])\n",
    "\n",
    "# # staves = getBoundedBoxes(final_image)\n",
    "# # cleaned_staves, staff_lines_positions = remove_staff_lines(staves)\n",
    "\n",
    "# print(staff_lines_positions)\n",
    "\n",
    "# for i, (stave, staff_lines) in enumerate(zip(cleaned_staves, staff_lines_positions)):\n",
    "#     notes = detect_notes(stave, staff_lines)\n",
    "#     print(f\"Detected Notes in Stave {i + 1}: {notes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
