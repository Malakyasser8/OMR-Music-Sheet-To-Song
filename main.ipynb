{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OMR Music Sheet to A MP3 file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "from skimage import img_as_ubyte\n",
    "import skimage as sk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.exposure import histogram\n",
    "from skimage.filters import threshold_otsu,threshold_local,median, unsharp_mask\n",
    "from matplotlib.pyplot import bar\n",
    "from skimage.color import rgb2gray,rgb2hsv\n",
    "from commonfunctions import *\n",
    "from scipy.ndimage import rotate\n",
    "from skimage.morphology import binary_erosion, binary_dilation, binary_closing, skeletonize, thin, binary_opening, remove_small_objects\n",
    "from skimage.measure import find_contours\n",
    "from skimage.draw import rectangle\n",
    "from skimage.transform import resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images,titles=None):\n",
    "    #This function is used to show image(s) with titles by sending an array of images and an array of associated titles.\n",
    "    # images[0] will be drawn with the title titles[0] if exists\n",
    "    # You aren't required to understand this function, use it as-is.\n",
    "    n_ims = len(images)\n",
    "    if titles is None: titles = ['(%d)' % i for i in range(1,n_ims + 1)]\n",
    "    fig = plt.figure()\n",
    "    n = 1\n",
    "    for image,title in zip(images,titles):\n",
    "        a = fig.add_subplot(1,n_ims,n)\n",
    "        if image.ndim == 2: \n",
    "            plt.gray()\n",
    "        plt.imshow(image)\n",
    "        a.set_title(title)\n",
    "        n += 1\n",
    "    fig.set_size_inches(np.array(fig.get_size_inches()) * n_ims)\n",
    "    plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equation(image):\n",
    "    shape=image.shape\n",
    "    H=np.zeros(256)\n",
    "    for x in range(0,shape[0]):\n",
    "        for y in range(0,shape[1]):\n",
    "            H[image[x][y]]+=1\n",
    "\n",
    "    return H\n",
    "\n",
    "\n",
    "def getThresholdRawan(img):\n",
    "    counts, _ = np.histogram(img, bins=256, range=(0, 256))\n",
    "    \n",
    "    total_pixels = np.sum(counts)\n",
    "    print(total_pixels)\n",
    "    Tinit = int(round(np.sum([i * counts[i] for i in range(256)]) / total_pixels))\n",
    "\n",
    "    \n",
    "    while True:\n",
    "        if np.sum(counts[:Tinit]) == 0 or np.sum(counts[Tinit:]) == 0:\n",
    "            return Tinit\n",
    "        lower = np.sum([i * counts[i] for i in range(Tinit)]) / np.sum(counts[:Tinit])\n",
    "        higher = np.sum([i * counts[i] for i in range(Tinit, 256)]) / np.sum(counts[Tinit:])\n",
    "        new_T = int((lower + higher) / 2)\n",
    "        if new_T == Tinit:\n",
    "            return new_T\n",
    "        Tinit = new_T\n",
    "\n",
    "def partition_imageRawan(img, n_partitions_horiz, n_partitions_vert):\n",
    "    print(img.shape)\n",
    "    height, width = img.shape\n",
    "    row_step = height // n_partitions_horiz\n",
    "    col_step = width // n_partitions_vert\n",
    "    \n",
    "    binary_img = np.zeros_like(img)\n",
    "    \n",
    "    for i in range(n_partitions_horiz):\n",
    "        for j in range(n_partitions_vert):\n",
    "            row_start = i * row_step\n",
    "            row_end = (i + 1) * row_step if i < n_partitions_horiz - 1 else height\n",
    "            col_start = j * col_step\n",
    "            col_end = (j + 1) * col_step if j < n_partitions_vert - 1 else width\n",
    "            \n",
    "            img_section = img[row_start:row_end, col_start:col_end]\n",
    "            threshold = getThresholdRawan(img_section)\n",
    "            binary_section = img_section > threshold\n",
    "            binary_img[row_start:row_end, col_start:col_end] = binary_section\n",
    "            \n",
    "    return binary_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getThreshold(image):\n",
    "    # image = (image * 255).astype('uint8')\n",
    "\n",
    "    counts, _ = np.histogram(image, bins=256, range=(0, 256))\n",
    "    \n",
    "    total_pixels = counts.sum()\n",
    "    gray_levels = np.arange(256)\n",
    "    Tinit = round((gray_levels * counts).sum() / total_pixels) \n",
    "    \n",
    "    while True:\n",
    "        lower_pixels = counts[:Tinit]\n",
    "        upper_pixels = counts[Tinit:]\n",
    "        \n",
    "        if lower_pixels.sum() == 0 or upper_pixels.sum() == 0:\n",
    "            break\n",
    "\n",
    "        lower_mean = (gray_levels[:Tinit] * lower_pixels).sum() / lower_pixels.sum()\n",
    "        upper_mean = (gray_levels[Tinit:] * upper_pixels).sum() / upper_pixels.sum()\n",
    "\n",
    "        new_threshold = round((lower_mean + upper_mean) / 2)\n",
    "        \n",
    "        if new_threshold == Tinit:\n",
    "            break\n",
    "        \n",
    "        Tinit = new_threshold\n",
    "    \n",
    "    binary_image = np.where(image < Tinit, 0, 255) # 0 is black, 255 is white\n",
    "    return binary_image\n",
    "\n",
    "\n",
    "def adaptive (image, NumberOfDivisions):\n",
    "    new_image = np.array_split(image, NumberOfDivisions, axis=1)\n",
    "    thresholded_images = []\n",
    "    for imagee in new_image:\n",
    "        threshold = getThreshold(imagee)\n",
    "        thresholded_images.append(threshold)    \n",
    "    \n",
    "    combined_image = np.block(thresholded_images)\n",
    "\n",
    "    return combined_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def deskew(original_img):\n",
    "    img = np.copy((original_img))\n",
    "    # Canny\n",
    "    imgCanny = sk.feature.canny(img, sigma=1.5)\n",
    "    thresh = sk.filters.threshold_otsu(imgCanny)\n",
    "    imgCanny = (imgCanny >= thresh)\n",
    "\n",
    "    # Apply Hough Transform\n",
    "    # Generates a list of 360 Radian degrees (-pi/2, pi/2)\n",
    "    angleSet = np.linspace(-np.pi, np.pi, 1440)\n",
    "    houghArr, theta, dis = sk.transform.hough_line(imgCanny, angleSet)\n",
    "\n",
    "    flatIdx = np.argmax(houghArr)\n",
    "    bestTheta = (flatIdx % theta.shape[0])\n",
    "    bestTheta = angleSet[bestTheta]\n",
    "    bestDis = np.int32(np.floor(flatIdx / theta.shape[0]))\n",
    "    bestDis = dis[bestDis]\n",
    "\n",
    "    # Rotate\n",
    "    thetaRotateDeg = (bestTheta*180)/np.pi\n",
    "    if thetaRotateDeg > 0:\n",
    "        thetaRotateDeg = thetaRotateDeg - 90\n",
    "    else:\n",
    "        thetaRotateDeg = thetaRotateDeg + 90\n",
    "\n",
    "    imgRotated = (sk.transform.rotate(\n",
    "        img, thetaRotateDeg, resize=True, mode='constant', cval=1))\n",
    "    return imgRotated\n",
    "\n",
    "def binarize(img, block_size=101):\n",
    "    t = sk.filters.threshold_local(img, block_size, offset=10)\n",
    "    img_b = img < t\n",
    "    return img_b\n",
    "\n",
    "\n",
    "\n",
    "def convertImgToUINT8(img_o):\n",
    "    img = np.copy(img_o)\n",
    "    img = img.astype(np.float64) / np.max(img)\n",
    "    img = 255 * img\n",
    "    img = img.astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "img = io.imread(\"./images/image2.png\",as_gray=True)\n",
    "if img.shape[0] > 1000 or img.shape[1] > 2000:\n",
    "        img = sk.transform.resize(img, (img.shape[0]//4, img.shape[1]//4))\n",
    "img1=deskew(img)\n",
    "img2 = convertImgToUINT8(img1)\n",
    "img3=binarize(img2)\n",
    "show_images([img3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = io.imread(\"./images/image.png\",as_gray=True)\n",
    "print(img.shape)\n",
    "# 1. Binarization\n",
    "\n",
    "# # Compute Otsu's threshold\n",
    "# otsu_threshold = threshold_otsu(img)\n",
    "# binary_image_ski = img > otsu_threshold\n",
    "\n",
    "#Adaptive ski\n",
    "# # Compute a local threshold\n",
    "# block_size = 201  # Size of the local region to consider\n",
    "# local_thresh = threshold_local(img, block_size, offset=0)\n",
    "\n",
    "#our threshold\n",
    "# print(img)\n",
    "# threshold=getThreshold(img)\n",
    "# img[img>threshold]=1\n",
    "# img[img<=threshold]=0\n",
    "\n",
    "show_images([img])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_binarization(input_image):\n",
    "    # Calculate the histogram of the input image\n",
    "    hist = cv2.calcHist([input_image], [0], None, [256], [0, 256])\n",
    "    # Normalize the histogram for easier analysis\n",
    "    normalized_hist = hist / hist.sum()\n",
    "    \n",
    "    # Check if the histogram has significant peaks near 0 and 255\n",
    "    near_zero = normalized_hist[:20].sum()  # Sum of bins near 0\n",
    "    near_255 = normalized_hist[-20:].sum()  # Sum of bins near 255\n",
    "\n",
    "    # Thresholds for determining scanned images\n",
    "    if near_zero+near_255 > 0.75:\n",
    "        # Use Otsu's binarization for scanned images\n",
    "        _, binarized_image = cv2.threshold(input_image, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    else:\n",
    "        # Apply both Otsu and Adaptive Thresholding\n",
    "        _, otsu_binary = cv2.threshold(input_image, 0, 255,cv2.THRESH_BINARY+ cv2.THRESH_OTSU)\n",
    "        adaptive_binary = cv2.adaptiveThreshold(input_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                                cv2.THRESH_BINARY, blockSize=9, C=5)\n",
    "        \n",
    "        # Calculate the number of black pixels for Otsu's output\n",
    "        otsu_black_pixels = np.sum(otsu_binary == 0)\n",
    "\n",
    "        # Threshold for deciding noise\n",
    "        noise_threshold = np.sum(hist[:120])\n",
    "\n",
    "        if otsu_black_pixels > noise_threshold:\n",
    "            # Otsu produces noise, use Adaptive Thresholding\n",
    "            binarized_image = adaptive_binary\n",
    "        else:\n",
    "            # Otsu works fine\n",
    "            binarized_image = otsu_binary\n",
    "\n",
    "    return binarized_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def resize_with_aspect_ratio(image, target_width, target_height, color=0):\n",
    "    # Get original dimensions\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # Calculate the scaling factor to maintain aspect ratio\n",
    "    scale = min(target_width / w, target_height / h)\n",
    "    \n",
    "    # Compute the new dimensions\n",
    "    new_width = int(w * scale)\n",
    "    new_height = int(h * scale)\n",
    "    \n",
    "    # Resize the image\n",
    "    resized_image = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Create a new blank image with the target dimensions\n",
    "    canvas =np.full((target_height, target_width), color, dtype=np.uint8)\n",
    "    \n",
    "    # Calculate padding to center the resized image\n",
    "    x_offset = (target_width - new_width) // 2\n",
    "    y_offset = (target_height - new_height) // 2\n",
    "    \n",
    "    # Place the resized image onto the canvas\n",
    "    canvas[y_offset:y_offset + new_height, x_offset:x_offset + new_width] = resized_image\n",
    "    \n",
    "    return canvas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread(\"./images/image11.png\")\n",
    "\n",
    "#remove noise using ski and opencv filters\n",
    "# remove_noise = median(img)\n",
    "remove_noise = cv2.bilateralFilter(img, 3, 75, 75)\n",
    "\n",
    "# show_images([remove_noise])\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(remove_noise, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#dynamic_binarization to apply any of otsu or adaptive\n",
    "binarized_image=dynamic_binarization(gray)\n",
    "\n",
    "# show_images([binarized_image],[\"binarized_image\"])\n",
    "\n",
    "edges = cv2.Canny(gray, 50, 150)\n",
    "\n",
    "#detect lines using Hough Transform\n",
    "lines = cv2.HoughLines(edges, 1, np.pi / 180.0, 250, np.array([]))\n",
    "\n",
    "rotated_image=binarized_image\n",
    "\n",
    "if lines is not None:  # Found lines\n",
    "    angles = []  # Store the angles of the detected lines\n",
    "    zero_angle_count = 0  # Count lines with angles close to 0°\n",
    "    tolerance_zero = 2.0  # Tolerance to consider an angle as 0° (degrees)\n",
    "\n",
    "    for line in lines:\n",
    "        rho, theta = line[0]\n",
    "        # Convert polar coordinates to Cartesian line endpoints\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        x1 = int(x0 + 1000 * (-b))  # Endpoint 1\n",
    "        y1 = int(y0 + 1000 * (a))\n",
    "        x2 = int(x0 - 1000 * (-b))  # Endpoint 2\n",
    "        y2 = int(y0 - 1000 * (a))\n",
    "\n",
    "        # # Draw the line on the output image\n",
    "        # cv2.line(output_image, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red line with thickness 2\n",
    "\n",
    "        # Convert angle to degrees\n",
    "        angle_degrees = 180 * theta / np.pi\n",
    "        angles.append(angle_degrees)\n",
    "\n",
    "        # Check if angle is close to 0° (horizontal line)\n",
    "        if abs(angle_degrees) < tolerance_zero or abs(angle_degrees - 180) < tolerance_zero:\n",
    "            zero_angle_count += 1\n",
    "\n",
    "    # Majority Check: If most lines are at zero angles, skip rotation\n",
    "    if zero_angle_count > len(angles) / 2:  # Majority condition\n",
    "        print(\"Majority of lines are horizontal. Skipping rotation.\")\n",
    "    else:\n",
    "        # Calculate the average angle excluding near-zero angles\n",
    "        average_angle = np.mean([angle for angle in angles if abs(angle) > tolerance_zero])\n",
    "        if(average_angle - 90)>2:\n",
    "            print(f\"Rotating by {average_angle - 90:.2f} degrees\")\n",
    "            rotated_image = rotate(rotated_image, average_angle - 90, cval=255)\n",
    "\n",
    "else:\n",
    "    print(\"No lines found\")\n",
    "\n",
    "\n",
    "rotated_image=255-rotated_image\n",
    "rotated_image=rotated_image>0\n",
    "final_image=remove_small_objects(rotated_image, 700, connectivity=8)\n",
    "\n",
    "show_images([final_image],[\"final_image\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect bounding boxes for staves\n",
    "\n",
    "def getBoundedBoxes(image):\n",
    "    #get staff bounding boxes whether they are connected or not\n",
    "    img_height=image.shape[0]\n",
    "    img_width=image.shape[1]\n",
    "\n",
    "    dilation = binary_dilation(image, footprint=np.ones((10, 1)))\n",
    "    # show_images([dilation], ['Dilation'])\n",
    "\n",
    "    closing = remove_small_objects(dilation, 200, connectivity=8)\n",
    "    show_images([closing], ['Closing and Small Object Removal'])\n",
    "\n",
    "\n",
    "    img_without_begin=closing[:,int(img_height*0.2):img_height]\n",
    "    show_images([closing,img_without_begin])\n",
    "\n",
    "    img_without_begin = (img_without_begin * 255).astype('uint8')\n",
    "    output_image = (image * 255).astype('uint8')\n",
    "\n",
    "\n",
    "    contours_without_begin, _ = cv2.findContours(img_without_begin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours_with_begin, _ = cv2.findContours(output_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    img_without_begin = cv2.cvtColor(img_without_begin, cv2.COLOR_GRAY2BGR)\n",
    "    output_image = cv2.cvtColor(output_image, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    #check if they are connected in the begining\n",
    "    staves=[]\n",
    "    correct_countours=contours_with_begin\n",
    "    is_correct_contours=False\n",
    "\n",
    "    if len(contours_with_begin) != len(contours_without_begin):\n",
    "        is_correct_contours=True\n",
    "        correct_countours=contours_without_begin\n",
    "        \n",
    "    for contour in correct_countours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        # cv2.rectangle(output_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        if(w>1.1*h and w*h > 50):\n",
    "            start_x = x\n",
    "            end_x = img_width\n",
    "            # print(\"width\",img_width)\n",
    "            # print(\"final_image shape\",image.shape)\n",
    "            if(is_correct_contours):\n",
    "                start_x=0\n",
    "            stave = output_image[y:y + h, start_x:end_x]\n",
    "            # print(\"Width\",w)\n",
    "            # print(\"Height\",h)\n",
    "            staves.append(stave)\n",
    "            show_images([stave], [\"Stave222\"])\n",
    "\n",
    "    return staves\n",
    "\n",
    "staves2= getBoundedBoxes(final_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_staff_lines(staves):\n",
    "    cleaned_staves = []\n",
    "    staff_lines_positions = []\n",
    "\n",
    "    for stave in staves:\n",
    "        # Invert stave to make lines white on black background\n",
    "        stave = 255 - stave\n",
    "        \n",
    "        # Edge detection for the stave\n",
    "        edges = cv2.Canny(stave, 50, 150, apertureSize=3)\n",
    "        show_images([edges], ['Edges'])\n",
    "\n",
    "        # Detect lines using Hough Transform\n",
    "        lines = cv2.HoughLinesP(edges, 1, np.pi / 180, threshold=100, minLineLength=50, maxLineGap=10)\n",
    "        \n",
    "        if lines is not None:\n",
    "            line_y_positions = []\n",
    "            for line in lines:\n",
    "                x1, y1, x2, y2 = line[0]\n",
    "                if abs(y2 - y1) < 5:  # Ensure the line is horizontal\n",
    "                    line_y_positions.append((y1 + y2) // 2)  # Average y-coordinate for the line\n",
    "\n",
    "            # Get 5 staff line positions by finding the most frequent y-coordinates\n",
    "            line_y_positions = sorted(line_y_positions)\n",
    "            staff_lines = []\n",
    "            for y in line_y_positions:\n",
    "                if not staff_lines or abs(y - staff_lines[-1]) > 5:  # Avoid duplicates\n",
    "                    staff_lines.append(y)\n",
    "            staff_lines_positions.append(staff_lines[:5])  # Ensure only 5 lines are kept\n",
    "        else:\n",
    "            staff_lines_positions.append([])  # No lines detected\n",
    "\n",
    "        stave_ratio = stave.shape[1]/stave.shape[0]\n",
    "        print(\"Stave ratio: \"+str(stave_ratio))\n",
    "\n",
    "\n",
    "        # Remove the detected staff lines from the stave image\n",
    "        horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (100, 1)) # x value of MORPH_RECT range [15-100] it depend on the zoom in of ------>\n",
    "        detected_lines = cv2.morphologyEx(stave, cv2.MORPH_OPEN, horizontal_kernel)\n",
    "        \n",
    "        show_images([detected_lines])\n",
    "\n",
    "        cleaned_image = stave - detected_lines\n",
    "        cleaned_image = cleaned_image > 0\n",
    "        dilated = binary_dilation(cleaned_image, footprint=np.ones((8, 1))) # 1st dilation depeneds on the zoom in , range [2-7] ------>\n",
    "\n",
    "        cleaned_staves.append(dilated)\n",
    "        # show_images([dilated], ['Cleaned Stave'])\n",
    "\n",
    "    return cleaned_staves, staff_lines_positions\n",
    "\n",
    "cleaned_staves, staff_lines_positions = remove_staff_lines(staves)\n",
    "show_images(cleaned_staves)\n",
    "print(staff_lines_positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_notes(cleaned_stave, staff_lines):\n",
    "    # Step 1: Remove staff lines\n",
    "    # stave_no_lines = cleaned_stave.copy()\n",
    "    # for line in staff_lines:\n",
    "    #     stave_no_lines[line - 2:line + 2, :] = 0  # Mask out staff lines (2-pixel width)\n",
    "    # Step 2: Use morphological operations to isolate note heads\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (25, 25)) # it get affected by the zoom in factor,range [(3,3) - (20,20)] ------> \n",
    "    processed_stave = cv2.morphologyEx(cleaned_stave.astype('uint8') * 255, cv2.MORPH_CLOSE, kernel)\n",
    "    processed_stave = cv2.morphologyEx(processed_stave.astype('uint8') * 255, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # Optional: Edge detection to highlight contours\n",
    "    edges = cv2.Canny((processed_stave * 255).astype('uint8'), 50, 150)\n",
    "    show_images([edges], ['Edges'])\n",
    "\n",
    "    # Step 3: Find contours\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    show_images([cv2.drawContours(processed_stave, contours, -1, (0, 255, 0), 2)], ['Contours'])\n",
    "\n",
    "    contours = sorted(contours, key=lambda contour: cv2.boundingRect(contour)[0])\n",
    "\n",
    "    notes = []\n",
    "\n",
    "    differences = [j - i for i, j in zip(staff_lines[:-1], staff_lines[1:])]\n",
    "    average_distance_between_spaces = sum(differences) / len(differences)\n",
    "    print(\"average dist: \" + str(average_distance_between_spaces))\n",
    "    \n",
    "    staff_lines.append(staff_lines[-1]+int(average_distance_between_spaces))\n",
    "    staff_lines.append(staff_lines[0]-int(average_distance_between_spaces))\n",
    "\n",
    "    staff_lines = sorted(staff_lines)\n",
    "\n",
    "    print(staff_lines)\n",
    "    notes=[]\n",
    "    for contour in contours:\n",
    "        # Filter based on contour size (area) and aspect ratio\n",
    "        area = cv2.contourArea(contour)\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        aspect_ratio = w / h if h > 0 else 0\n",
    "\n",
    "        factor = 12 # this factor is for the value of zoom in\n",
    "        print(\"area: \" + str(area) + \", aspect ratio: \" + str(aspect_ratio))\n",
    "        if (10 * factor) < area < (300 * factor) and 0.7 < aspect_ratio < 1.3:  # Typical note head properties  area varies with the zoom in, range [300] --------->\n",
    "            note_center = y + h // 2  # Vertical center of the note head\n",
    "\n",
    "            print(\"note center: \" + str(note_center) + \",x= \" + str(x) + \",y1= \" + str(y) +\",y2= \" + str(y+h))\n",
    "\n",
    "            note_names_treble = ['C','D','E','F','G','A','B','C2','D2','E2','F2','G2','A2','B2']\n",
    "            y1=y + int(average_distance_between_spaces/ 8)\n",
    "            y2=y+h - int(average_distance_between_spaces/ 8)\n",
    "\n",
    "            if  y2>staff_lines[-1] and y1<staff_lines[-1]:\n",
    "                notes.append('C')\n",
    "            elif y2<=staff_lines[-1] and y1>=staff_lines[-2]:\n",
    "                notes.append('D')\n",
    "            elif y2>staff_lines[-2] and y1<staff_lines[-2]:\n",
    "                notes.append('E')\n",
    "            elif y2<=staff_lines[-2] and y1>=staff_lines[-3]:\n",
    "                notes.append('F')\n",
    "            elif y2>staff_lines[-3] and y1<staff_lines[-3]:\n",
    "                notes.append('G')\n",
    "            elif y2<=staff_lines[-3] and y1>=staff_lines[-4]:\n",
    "                notes.append('A')\n",
    "            elif y2>staff_lines[-4] and y1<staff_lines[-4]:\n",
    "                notes.append('B')\n",
    "            elif y2<=staff_lines[-4] and y1>=staff_lines[-5]:\n",
    "                notes.append('C2')\n",
    "            elif y2>staff_lines[-5] and y1<staff_lines[-5]:\n",
    "                notes.append('D2')\n",
    "            elif y2<=staff_lines[-5] and y1>=staff_lines[-6]:\n",
    "                notes.append('E2')\n",
    "            elif y2>staff_lines[-6] and y1<staff_lines[-6]:\n",
    "                notes.append('F2')\n",
    "            elif y2<=staff_lines[-6] and y1>=staff_lines[-7]:\n",
    "                notes.append('A2')\n",
    "            elif y2>staff_lines[-7] and y1<staff_lines[-7]:\n",
    "                notes.append('B2')\n",
    "\n",
    "    \n",
    "    return notes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to map note positions to musical notes\n",
    "def map_positions_to_notes(positions, clef='treble'):\n",
    "    note_names_treble = ['F', 'E', 'D', 'C', 'B', 'A', 'G']\n",
    "    note_names_bass = ['A', 'G', 'F', 'E', 'D', 'C', 'B']\n",
    "    \n",
    "    note_names = note_names_treble if clef == 'treble' else note_names_bass\n",
    "    mapped_notes = [note_names[pos % len(note_names)] for pos in positions if pos >= 0]\n",
    "    return mapped_notes\n",
    "\n",
    "# Main processing\n",
    "# final_image = cv2.imread('sheet_music.png', cv2.IMREAD_GRAYSCALE)  # Load your image here\n",
    "# final_image = final_image < 128  # Binarize the image\n",
    "# show_images([final_image], [\"Final Image\"])\n",
    "\n",
    "# staves = getBoundedBoxes(final_image)\n",
    "# cleaned_staves, staff_lines_positions = remove_staff_lines(staves)\n",
    "\n",
    "print(staff_lines_positions)\n",
    "\n",
    "for i, (stave, staff_lines) in enumerate(zip(cleaned_staves, staff_lines_positions)):\n",
    "    notes = detect_notes(stave, staff_lines)\n",
    "    print(f\"Detected Notes in Stave {i + 1}: {notes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
